#!/usr/bin/env python3
"""
Test Integrated DAG Execution
=============================

Test that the integrated DAG executor works with parallel branches
in the main workflow system.
"""

import os
import uuid
import asyncio
import time
from pathlib import Path
from dotenv import load_dotenv

# Load environment
env_path = Path(__file__).parent / "creds.env"
load_dotenv(env_path)

from iointel.src.agent_methods.data_models.workflow_spec import (
    WorkflowSpec, NodeSpec, NodeData, EdgeSpec
)
from iointel.src.workflow import Workflow
from iointel.src.utilities.registries import TOOLS_REGISTRY
from iointel.src.utilities.decorators import register_custom_task

# Import the example tools to register them globally
import iointel.src.RL.example_tools


# Register tool executor with timing
@register_custom_task("tool")
async def timed_tool_executor(task_metadata, objective, agents, execution_metadata):
    """Tool executor that tracks execution timing."""
    tool_name = task_metadata.get("tool_name")
    config = task_metadata.get("config", {})
    
    start_time = time.time()
    print(f"    üîß [{start_time:.3f}] Starting {tool_name}")
    
    tool = TOOLS_REGISTRY.get(tool_name)
    if not tool:
        raise ValueError(f"Tool '{tool_name}' not found")
    
    # Add small delay to make timing visible
    await asyncio.sleep(0.1)
    
    result = await tool.run(config)
    end_time = time.time()
    
    print(f"    ‚úÖ [{end_time:.3f}] {tool_name} completed in {end_time - start_time:.3f}s ‚Üí {result}")
    return result


async def test_integrated_parallel_execution():
    """Test parallel execution through the integrated workflow system."""
    print("üöÄ Testing Integrated DAG Execution with Parallel Branches...")
    
    # Create parallel branches workflow: A ‚Üí (B, C) ‚Üí D
    workflow_spec = WorkflowSpec(
        id=uuid.uuid4(),
        rev=1,
        title="Integrated Parallel Test",
        description="Test parallel execution through integrated workflow system",
        nodes=[
            NodeSpec(
                id="source",
                type="tool",
                label="Source: Add 10+5",
                data=NodeData(
                    tool_name="add",
                    config={"a": 10, "b": 5},
                    outs=["result"]
                )
            ),
            NodeSpec(
                id="branch_left",
                type="tool",
                label="Left Branch: Square",
                data=NodeData(
                    tool_name="multiply",
                    config={"a": "{source}", "b": "{source}"},  # Square it
                    ins=["result"],
                    outs=["result"]
                )
            ),
            NodeSpec(
                id="branch_right",
                type="tool",
                label="Right Branch: Double",
                data=NodeData(
                    tool_name="multiply",
                    config={"a": "{source}", "b": 2},
                    ins=["result"],
                    outs=["result"]
                )
            ),
            NodeSpec(
                id="merge",
                type="tool",
                label="Merge: Add branches",
                data=NodeData(
                    tool_name="add",
                    config={"a": "{branch_left}", "b": "{branch_right}"},
                    ins=["left", "right"],
                    outs=["result"]
                )
            )
        ],
        edges=[
            EdgeSpec(id="source_to_left", source="source", target="branch_left"),
            EdgeSpec(id="source_to_right", source="source", target="branch_right"),
            EdgeSpec(id="left_to_merge", source="branch_left", target="merge"),
            EdgeSpec(id="right_to_merge", source="branch_right", target="merge")
        ]
    )
    
    # Convert to executable workflow
    workflow_def = workflow_spec.to_workflow_definition()
    yaml_content = workflow_spec.to_yaml()
    
    # Create workflow from YAML
    workflow = Workflow.from_yaml(yaml_str=yaml_content)
    
    print(f"  üìä Workflow has {len(workflow.tasks)} tasks")
    
    # Execute with timing
    print("  ‚è±Ô∏è  Executing workflow...")
    start_time = time.time()
    
    results = await workflow.run_tasks()
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    print(f"  üéâ Workflow completed in {execution_time:.3f}s")
    print(f"  üìä Results: {results['results']}")
    
    # Verify mathematical correctness
    # source=15, branch_left=15¬≤=225, branch_right=15*2=30, merge=225+30=255
    assert results["results"]["source"] == 15.0
    assert results["results"]["branch_left"] == 225.0
    assert results["results"]["branch_right"] == 30.0
    assert results["results"]["merge"] == 255.0
    
    # Check if execution was parallel (should be faster than sequential)
    # Sequential would be ~0.4s (4 tasks * 0.1s each)
    # Parallel should be ~0.3s (3 batches: source, parallel branches, merge)
    if execution_time < 0.35:
        print("  ‚úÖ Execution time suggests parallel execution!")
    else:
        print(f"  ‚ö†Ô∏è  Execution time {execution_time:.3f}s seems sequential")
    
    print("  ‚úÖ Integrated DAG execution works!")


async def main():
    """Run the integrated DAG test."""
    print("üî• Integrated DAG Execution Test")
    print("=" * 50)
    
    try:
        await test_integrated_parallel_execution()
        print("\nüéâ INTEGRATION SUCCESS!")
        print("‚úÖ DAG executor integrated into workflow system")
        print("‚úÖ Parallel execution working end-to-end")
        print("‚úÖ Data flow resolution working with DAG topology")
        
    except Exception as e:
        print(f"\n‚ùå INTEGRATION TEST FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    asyncio.run(main())