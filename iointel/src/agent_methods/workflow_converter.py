"""
Workflow Converter - Transforms LLM-generated WorkflowSpec to executable WorkflowDefinition.

This module provides the bridge between the clean, minimal workflow specifications
generated by the LLM and the rich, executable workflow definitions used by the system.
"""

from typing import Dict, List, Optional

from .data_models.workflow_spec import WorkflowSpec, NodeSpec, EdgeSpec
from .data_models.datamodels import (
    WorkflowDefinition,
    TaskDefinition,
    AgentParams
)
from ..utilities.registries import TOOLS_REGISTRY
from ..utilities.helpers import make_logger

logger = make_logger(__name__)


class WorkflowConverter:
    """Converts LLM-generated WorkflowSpec to system WorkflowDefinition."""
    
    def __init__(
        self,
        default_agents: Optional[List[AgentParams]] = None,
        default_timeout: int = 60,
        default_retries: int = 3,
        default_client_mode: bool = True
    ):
        """
        Initialize the converter with system defaults.
        
        Args:
            default_agents: Default agents to assign to tasks
            default_timeout: Default timeout in seconds
            default_retries: Default number of retries
            default_client_mode: Default client mode setting
        """
        self.default_agents = default_agents or []
        self.default_timeout = default_timeout
        self.default_retries = default_retries
        self.default_client_mode = default_client_mode
    
    def convert(self, spec: WorkflowSpec) -> WorkflowDefinition:
        """
        Convert a WorkflowSpec to WorkflowDefinition.
        
        Args:
            spec: LLM-generated workflow specification
            
        Returns:
            WorkflowDefinition ready for execution
        """
        logger.info(f"Converting WorkflowSpec '{spec.title}' to WorkflowDefinition")
        
        # Convert nodes to tasks
        tasks = self._convert_nodes_to_tasks(spec.nodes, spec.edges)
        
        # Create workflow definition with DAG metadata
        workflow_def = WorkflowDefinition(
            name=spec.title,
            objective=spec.description,
            client_mode=self.default_client_mode,
            agents=self.default_agents,
            tasks=tasks
        )
        
        # Store DAG structure metadata for execution engine
        if tasks:
            # Add DAG metadata to the first task so workflow can detect DAG structure
            first_task = tasks[0]
            if isinstance(first_task, dict):
                # Handle dict-based task
                if 'task_metadata' not in first_task:
                    first_task['task_metadata'] = {}
                first_task['task_metadata']['dag_structure'] = {
                    'nodes': [node.model_dump() for node in spec.nodes],
                    'edges': [edge.model_dump() for edge in spec.edges],
                    'original_spec_id': str(spec.id)
                }
            else:
                # Handle TaskDefinition object
                if first_task.task_metadata is None:
                    first_task.task_metadata = {}
                first_task.task_metadata['dag_structure'] = {
                    'nodes': [node.model_dump() for node in spec.nodes],
                    'edges': [edge.model_dump() for edge in spec.edges],
                    'original_spec_id': str(spec.id)
                }
        
        logger.info(f"Successfully converted workflow with {len(tasks)} tasks and {len(spec.edges)} edges")
        return workflow_def
    
    def _convert_nodes_to_tasks(
        self,
        nodes: List[NodeSpec],
        edges: List[EdgeSpec]
    ) -> List[TaskDefinition]:
        """Convert nodes to task definitions."""
        tasks = []
        
        # Build edge lookup for dependencies
        edge_map = self._build_edge_map(edges)
        
        for node in nodes:
            task = self._convert_node_to_task(node, edge_map.get(node.id, []))
            tasks.append(task)
        
        return tasks
    
    def _convert_node_to_task(
        self,
        node: NodeSpec,
        incoming_edges: List[EdgeSpec]
    ) -> TaskDefinition:
        """Convert a single node to a task definition."""
        # Base task metadata
        task_metadata = {
            "config": node.data.config,
            "ports": {
                "inputs": node.data.ins,
                "outputs": node.data.outs
            }
        }
        
        # Add node-type specific metadata
        if node.type == "data_source" and node.data.source_name:
            task_metadata["tool_name"] = node.data.source_name  # Keep tool_name for backward compatibility
            
            # Validate source exists
            if node.data.source_name not in TOOLS_REGISTRY:
                logger.warning(f"Data source '{node.data.source_name}' not found in registry")
        
        elif node.type == "agent" and node.data.agent_instructions:
            task_metadata["agent_instructions"] = node.data.agent_instructions
            # Add tools to task metadata so they're available to execute_agent_task
            if node.data.tools:
                task_metadata["tools"] = node.data.tools
        
        elif node.type == "workflow_call" and node.data.workflow_id:
            task_metadata["workflow_id"] = node.data.workflow_id
        
        # Build execution metadata with system defaults
        execution_metadata = {
            "timeout": self.default_timeout,
            "retries": self.default_retries,
            "client_mode": self.default_client_mode
        }
        
        # Add edge conditions if any
        conditions = [edge.data.condition for edge in incoming_edges if edge.data.condition]
        if conditions:
            execution_metadata["preconditions"] = conditions
        
        # Create task definition
        task = TaskDefinition(
            task_id=node.id,
            name=node.label,
            type=node.type,
            objective=f"Execute {node.label}",
            agents=self._get_agents_for_node(node),
            task_metadata=task_metadata,
            execution_metadata=execution_metadata
        )
        
        return task
    
    def _get_agents_for_node(self, node: NodeSpec) -> Optional[List[AgentParams]]:
        """Determine which agents should execute this node."""
        # For agent nodes, prefer custom agents if provided, otherwise create from node data
        if node.type == "agent":
            if node.data.agent_instructions:
                # If custom agents provided, use them but update with node-specific instructions and tools
                if self.default_agents:
                    # Clone the first custom agent and update with node-specific instructions
                    custom_agent = self.default_agents[0]
                    
                    # Load tools for the agent - prefer node-specific tools, fall back to custom agent tools
                    agent_tools = []
                    tools_to_load = node.data.tools or custom_agent.tools or []
                    
                    if tools_to_load:
                        for tool_name in tools_to_load:
                            if tool_name in TOOLS_REGISTRY:
                                agent_tools.append(tool_name)
                                print(f"üîß Loading tool '{tool_name}' for agent '{node.id}'")
                                logger.info(f"Loading tool '{tool_name}' for agent '{node.id}'")
                            else:
                                # For tests and development, include tools even if not in registry
                                agent_tools.append(tool_name)
                                print(f"‚ö†Ô∏è  Tool '{tool_name}' not found in registry for agent '{node.id}' - including anyway")
                                logger.warning(f"Tool '{tool_name}' not found in registry for agent '{node.id}'")
                    
                    # Use centralized model configuration, but prefer custom agent model over node model
                    from ..utilities.constants import get_model_config
                    # Custom agent model takes precedence over node model when custom agents are provided
                    preferred_model = custom_agent.model or node.data.model
                    config = get_model_config(
                        model=preferred_model,
                        api_key=None,  # Let it use defaults
                        base_url=None  # Let it use defaults
                    )
                    
                    # Always use the resolved model from config (which honors the preferred_model)
                    model = config["model"]
                    api_key = config["api_key"]
                    base_url = config["base_url"]
                    
                    if hasattr(custom_agent, 'model_copy'):
                        # Pydantic v2 style
                        agent_params = custom_agent.model_copy(update={
                            "name": f"agent_{node.id}",
                            "instructions": node.data.agent_instructions,
                            "model": model,
                            "api_key": api_key,
                            "base_url": base_url,
                            "tools": agent_tools  # üîë Update with node-specific tools!
                        })
                    else:
                        # Pydantic v1 style or manual copy
                        agent_params = AgentParams(
                            name=f"agent_{node.id}",
                            instructions=node.data.agent_instructions,
                            model=model,
                            api_key=api_key,
                            base_url=base_url,
                            tools=agent_tools,  # üîë Use node-specific tools!
                            context=getattr(custom_agent, 'context', None),
                            persona=getattr(custom_agent, 'persona', None),
                            model_settings=getattr(custom_agent, 'model_settings', None),
                        )
                    return [agent_params]
                else:
                    # No custom agents, create from node data
                    
                    # Load tools for the agent if specified
                    agent_tools = []
                    if node.data.tools:
                        for tool_name in node.data.tools:
                            if tool_name in TOOLS_REGISTRY:
                                agent_tools.append(tool_name)
                                print(f"üîß Loading tool '{tool_name}' for agent '{node.id}'")
                                logger.info(f"Loading tool '{tool_name}' for agent '{node.id}'")
                            else:
                                print(f"‚ö†Ô∏è  Tool '{tool_name}' not found in registry for agent '{node.id}'")
                                logger.warning(f"Tool '{tool_name}' not found in registry for agent '{node.id}'")
                    
                    # Use centralized model configuration
                    from ..utilities.constants import get_model_config
                    model_config = get_model_config(
                        model=node.data.model,
                        api_key=None,  # Let it use defaults
                        base_url=None  # Let it use defaults
                    )
                    model = model_config["model"]
                    api_key = model_config["api_key"]
                    base_url = model_config["base_url"]
                    
                    # Handle None node config gracefully
                    node_config = node.data.config or {}
                    
                    # Ensure node_config is a dict (defensive programming)
                    if not isinstance(node_config, dict):
                        logger.warning(f"Node {node.id} config is not a dict: {type(node_config)}, using empty dict")
                        node_config = {}
                    
                    agent_params = AgentParams(
                        name=f"agent_{node.id}",
                        instructions=node.data.agent_instructions,
                        model=model,
                        api_key=api_key,
                        base_url=base_url,
                        tools=agent_tools,  # üîë Load tools for the agent!
                        context=node_config.get("context") if node_config else None,
                        persona=node_config.get("persona") if node_config else None,
                        model_settings=node_config.get("model_settings") if node_config else None,
                    )
                    return [agent_params]
            else:
                # Fallback to default agents if no instructions
                return self.default_agents
        
        # Data source nodes typically don't need agents
        if node.type == "data_source":
            return None
        
        # Workflow calls might need agents for coordination
        return self.default_agents
    
    def _build_edge_map(self, edges: List[EdgeSpec]) -> Dict[str, List[EdgeSpec]]:
        """Build a map of target node ID to incoming edges."""
        edge_map = {}
        
        for edge in edges:
            if edge.target not in edge_map:
                edge_map[edge.target] = []
            edge_map[edge.target].append(edge)
        
        return edge_map


def spec_to_yaml(spec: WorkflowSpec, **converter_kwargs) -> str:
    """
    Convert a WorkflowSpec to YAML format.
    
    Args:
        spec: The workflow specification to convert
        **converter_kwargs: Arguments passed to WorkflowConverter
        
    Returns:
        YAML string representation
    """
    import yaml
    
    converter = WorkflowConverter(**converter_kwargs)
    workflow_def = converter.convert(spec)
    
    # Convert to dict and dump as YAML
    workflow_dict = workflow_def.model_dump(mode="json")
    return yaml.safe_dump(workflow_dict, sort_keys=False)


def spec_to_definition(
    spec: WorkflowSpec,
    agents: Optional[List[AgentParams]] = None,
    **kwargs
) -> WorkflowDefinition:
    """
    Convenience function to convert WorkflowSpec to WorkflowDefinition.
    
    Args:
        spec: The workflow specification
        agents: Optional agents to assign
        **kwargs: Additional converter arguments
        
    Returns:
        WorkflowDefinition ready for execution
    """
    converter = WorkflowConverter(default_agents=agents, **kwargs)
    return converter.convert(spec)


def update_workflow_api_keys(workflow_def, debug: bool = False):
    """
    Post-DAG introspection to update API keys for all agents in a workflow.
    
    This function ensures all agents have the correct API keys and base URLs
    for their specified models, especially important for Llama models that
    need IO Intel API configuration.
    
    Args:
        workflow_def: WorkflowDefinition to update
        debug: Whether to print debug information
        
    Returns:
        Updated WorkflowDefinition with proper API configuration
    """
    from ..utilities.constants import get_model_config
    
    if debug:
        print("üîß Updating workflow API keys for all agents...")
    
    # Update default agents
    if workflow_def.agents:
        for i, agent in enumerate(workflow_def.agents):
            if hasattr(agent, 'model') and agent.model:
                config = get_model_config(
                    model=agent.model,
                    api_key=getattr(agent, 'api_key', None),
                    base_url=getattr(agent, 'base_url', None)
                )
                
                # Update agent configuration
                agent.api_key = config["api_key"]
                agent.base_url = config["base_url"]
                agent.model = config["model"]  # Ensure model is canonical
                
                if debug:
                    print(f"   ü§ñ Updated default agent {i}: {agent.model} -> {config['base_url']}")
    
    # Update task-level agents
    for task in workflow_def.tasks:
        if hasattr(task, 'agents') and task.agents:
            for agent in task.agents:
                if hasattr(agent, 'model') and agent.model:
                    config = get_model_config(
                        model=agent.model,
                        api_key=getattr(agent, 'api_key', None),
                        base_url=getattr(agent, 'base_url', None)
                    )
                    
                    # Update agent configuration
                    agent.api_key = config["api_key"]
                    agent.base_url = config["base_url"]
                    agent.model = config["model"]  # Ensure model is canonical
                    
                    if debug:
                        print(f"   ü§ñ Updated task agent '{agent.name}': {agent.model} -> {config['base_url']}")
    
    if debug:
        print("‚úÖ Workflow API key update complete")
    
    return workflow_def